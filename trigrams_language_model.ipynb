{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigram Lyrics generation\n",
    "\n",
    "## Sample sentence: \n",
    "Carlos needs a haircut\n",
    "\n",
    "## Bigrams: \n",
    "\n",
    "- (Carlos, needs)\n",
    "- (needs, a)\n",
    "- (a, haircut)\n",
    "\n",
    "## Trigrams\n",
    "\n",
    "- (Carlos, needs, a)\n",
    "- (needs, a, haircut)\n",
    "\n",
    "## Acknowledgments\n",
    "Based on the Poetry-generator talk made by Carlos Castro - Software Engineer at Microsoft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\lirosale\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lirosale\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download data\n",
    "\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.']\n"
     ]
    }
   ],
   "source": [
    "# Inspect first sentence\n",
    "\n",
    "first_sentence = reuters.sents()[0]\n",
    "print(first_sentence) # [u'ASIAN', u'EXPORTERS', u'FEAR', u'DAMAGE', u'FROM' ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, None, 'ASIAN'), (None, 'ASIAN', 'EXPORTERS'), ('ASIAN', 'EXPORTERS', 'FEAR'), ('EXPORTERS', 'FEAR', 'DAMAGE'), ('FEAR', 'DAMAGE', 'FROM'), ('DAMAGE', 'FROM', 'U'), ('FROM', 'U', '.'), ('U', '.', 'S'), ('.', 'S', '.-'), ('S', '.-', 'JAPAN'), ('.-', 'JAPAN', 'RIFT'), ('JAPAN', 'RIFT', 'Mounting'), ('RIFT', 'Mounting', 'trade'), ('Mounting', 'trade', 'friction'), ('trade', 'friction', 'between'), ('friction', 'between', 'the'), ('between', 'the', 'U'), ('the', 'U', '.'), ('U', '.', 'S'), ('.', 'S', '.'), ('S', '.', 'And'), ('.', 'And', 'Japan'), ('And', 'Japan', 'has'), ('Japan', 'has', 'raised'), ('has', 'raised', 'fears'), ('raised', 'fears', 'among'), ('fears', 'among', 'many'), ('among', 'many', 'of'), ('many', 'of', 'Asia'), ('of', 'Asia', \"'\"), ('Asia', \"'\", 's'), (\"'\", 's', 'exporting'), ('s', 'exporting', 'nations'), ('exporting', 'nations', 'that'), ('nations', 'that', 'the'), ('that', 'the', 'row'), ('the', 'row', 'could'), ('row', 'could', 'inflict'), ('could', 'inflict', 'far'), ('inflict', 'far', '-'), ('far', '-', 'reaching'), ('-', 'reaching', 'economic'), ('reaching', 'economic', 'damage'), ('economic', 'damage', ','), ('damage', ',', 'businessmen'), (',', 'businessmen', 'and'), ('businessmen', 'and', 'officials'), ('and', 'officials', 'said'), ('officials', 'said', '.'), ('said', '.', None), ('.', None, None)]\n"
     ]
    }
   ],
   "source": [
    "# Show trigrams for first sentence\n",
    "\n",
    "print(list(trigrams(first_sentence, pad_left=True, pad_right=True))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many trigrams in n word sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "# Word count\n",
    "print(len(first_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "# Trigram count\n",
    "print(len(list(trigrams(first_sentence, pad_left=True, pad_right=True))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuters trigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our model will be a dictionary that maps trigram -> number of occurrences in reuters data\n",
    "# By default we have zero for all trigrams (this is why we use defaultdict and not dict)\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    " \n",
    "# Iterated through all sentences in the dataset\n",
    "for sentence in reuters.sents():\n",
    "    # For each trigram in the sentence\n",
    "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "        # Increase occurence count\n",
    "        model[(w1, w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times does \"economists\" follow \"what the\"?\n",
    "#print(model[\"\", \"\"][\"\"]) # \"economists\" follows \"what the\" 2 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times does \"noneexistingword\" follow \"what the\"?\n",
    "#print(model[\"\", \"\"][\"\"]) # 0 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model[\"\",\"\"][\"\"]) # 8839 sentences start with \"The\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition for probabilities in trigram model\n",
    "\n",
    "Consider the sentences \n",
    "\n",
    "- _Carlos needs a haircut_\n",
    "- _Carlos needs a new pair of shoes_\n",
    "\n",
    "The trigrams are\n",
    "\n",
    "- (Carlos, needs, a) (2)\n",
    "- (needs, a, haircut) (1)\n",
    "- (needs, a, new) (1)\n",
    "- (a, new, pair) (1)\n",
    "- (pair, of, shoes) (1)\n",
    "\n",
    "Our language model can now predict conditional probabilities for words given the context:\n",
    "\n",
    "Carlos, needs -> ???\n",
    "\n",
    "a: 1.0\n",
    "carlos: 0.0\n",
    "needs: 0.0\n",
    "new: 0.0\n",
    "haircut: 0.0\n",
    "shoes: 0.0\n",
    "\n",
    "needs, a ->\n",
    "\n",
    "\n",
    "a: 0.0\n",
    "carlos: 0.0\n",
    "needs: 0.0\n",
    "new: 0.5\n",
    "haircut: 0.5\n",
    "shoes: 0.0\n",
    "\n",
    "Mathematically this can be expressed as the conditional probability P (w[i] | w[i-1], w[i-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuters trigram text generation\n",
    "\n",
    "Let's get a word prediction given 2 words from our trigram model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398630\n"
     ]
    }
   ],
   "source": [
    "print(len(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute probabilities from counts\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    #print(w1_w2, total_count)\n",
    "    for w3 in model[w1_w2]:\n",
    "        # Divide the number of times a trigram appears by the total count of trigrams\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View language model output for \"what the\"\n",
    "prediction = model[\"I\", \"Shall\"]\n",
    "\n",
    "prediction_sorted = sorted(prediction.items(), key=lambda kv: -kv[1])\n",
    "\n",
    "for word, conditional_probability in prediction_sorted:\n",
    "    print(word, conditional_probability)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, 'On', 'the', 'other', 'three', 'trading', 'banks', '.', None]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import compress\n",
    "\n",
    "text = [None, None]\n",
    "end_sentence = False\n",
    "\n",
    "while not end_sentence:\n",
    "    \n",
    "    # Obtain predictions for next word based on the lastest 2 words\n",
    "    predictions = model[tuple(text[-2:])]\n",
    " \n",
    "    prediction_items = predictions.items()\n",
    "    probs = [p[1] for p in prediction_items]\n",
    "    words = [p[0] for p in prediction_items]\n",
    "    \n",
    "    # Randomly select next word considering conditional probabilities\n",
    "    s = np.random.multinomial(1, probs) # [0 0 0 1 0 0 0]\n",
    "    candidate = list(compress(words, s))[0]\n",
    "    text.append(candidate)\n",
    "    \n",
    "    if candidate == None:\n",
    "        end_sentence = True\n",
    "\n",
    "print(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load poetry\n",
    "file = open(\"DonOmar/Cuentale.txt\", \"r\") \n",
    "\n",
    "new_line_sentinel = \" _NL_ \"\n",
    "\n",
    "# In poetry, as in music, new lines are very important. Workaround to capture the new line in the tokenizer\n",
    "song = file.read().replace(\"\\n\", new_line_sentinel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Eliel (Eliel!) _NL_ Tu sabes _NL_ Quien mas? (quien mas?) _NL_ Tu sabes! _NL_ Si es el nene de titi _NL_ El nene de titi _NL_ King of Kings _NL_ Tu sabes! _NL_ Pa la tigerada _NL_ Mira si ya to' el mundo lo sabe _NL_ Tu sabes! _NL_ La calle sabe! (la calle lo sabe) _NL_ Lo saben ya! _NL_ Tu sabes! _NL_  _NL_ Eliel (Eliel!) _NL_ Tu sabes _NL_ Quien mas? (quien mas?) _NL_ Tu sabes! _NL_ Si es el nene de titi _NL_ El nene de titi _NL_ King of Kings _NL_ Tu sabes! _NL_ Pa la tigerada _NL_ Mira si ya to' el mundo lo sabe _NL_ Tu sabes! _NL_ La calle sabe! (la calle lo sabe) _NL_ Lo saben ya! _NL_ Tu sabes! _NL_ Tu sabes _NL_ Quien mas? (quien mas?) _NL_ Tu sabes! _NL_ Si es el nene de titi _NL_ El nene de titi _NL_ King of Kings _NL_ Tu sabes! _NL_ Pa la tigerada _NL_ Mira si ya to' el mundo lo sabe _NL_ Tu sabes! _NL_ La calle sabe! (la calle lo sabe) _NL_ Lo saben ya! _NL_ Tu sabes!Anda vamos… _NL_ Cuentale de tu y yo _NL_ Y de una vez confiesale _NL_ Que te perdio _NL_ Anda vamos… _NL_ Cuentale de tu y yo _NL_ Y de una vez confiesale _NL_ Que te perdioAnda vamos… _NL_ Cuentale de esta pasion _NL_ Por que ya yo no esperare _NL_ O le dices tu, o le digo yo _NL_ Anda vamos… _NL_ Cuentale de esta pasion _NL_ Por que ya yo no esperare _NL_ O le dices tu, o le digo yoDe ti, de mi, de mi, de ti… _NL_ De ti, de mi, de mi, de ti, de ti, de mi, de mi, de ti… _NL_ De ti, de mi, de mi, de ti… _NL_ De ti, de mi, de mi, de ti, de ti, de mi, de mi, de ti… _NL_ De ti, de mi, de mi, de ti… _NL_ De ti, de mi, de mi, de ti, de ti, de mi, de mi, de ti… _NL_ De ti, de mi, de mi, de ti… _NL_ De ti, de mi, de mi, de ti, de ti, de mi, de mi, de ti…Ay cuentale… que ya tu boca _NL_ Pide mis besos que la vuelven loca _NL_ Y hablale de esas otras cosas… _NL_ De los poemas y tambien las rosas _NL_ Hablale de esas tus salidas… _NL_ Dale en las noche pa' verme a escondia _NL_ Y ya no le digas mas mentiras _NL_ Confiesale que tu hoy en dia eres mia. _NL_ Ay cuentale… que ya tu boca _NL_ Pide mis besos que la vuelven loca _NL_ Y hablale de esas otras cosas… _NL_ De los poemas y tambien las rosas _NL_ Hablale de esas tus salidas… _NL_ Dale en las noche pa' verme a escondia _NL_ Y ya no le digas mas mentiras _NL_ Confiesale que tu hoy en dia eres mia.De ti, de mi, de mi, de ti… _NL_ De ti, de mi, de mi, de ti, de ti, de mi, de mi, de ti… _NL_ Ay!! De ti, de mi, de mi, de ti… _NL_ De ti, de mi, de mi, de ti, de ti, de mi, de mi, de ti… _NL_ De ti, de mi, de mi, de ti… _NL_ De ti, de mi, de mi, de ti, de ti, de mi, de mi, de ti… _NL_ Ay!! De ti, de mi, de mi, de ti… _NL_ De ti, de mi, de mi, de ti, de ti, de mi, de mi, de ti…Ay hablable… _NL_ De lo que hicimos y cuentale como nos sentimos _NL_ Confiesale, que somos uno _NL_ Que yo te di… lo que el no pudo _NL_ Ay hablable… _NL_ De lo que hicimos y cuentale como nos sentimos _NL_ Confiesale, que somos uno _NL_ Que yo te di… lo que el no pudoY hablable… _NL_ De lo que hicimos y cuentale como nos sentimos _NL_ Confiesale, que somos uno _NL_ Que yo te di… lo que el no pudo _NL_ Y hablable… _NL_ De lo que hicimos y cuentale como nos sentimos _NL_ Confiesale, que somos uno _NL_ Que yo te di… lo que el no pudoY que el negro se menea… _NL_ Se menea, se menea, se menea _NL_ Se menea, se menea, se menea _NL_ Se menea _NL_ Te vuelves loca cuando _NL_ Bailotea, machequea _NL_ Como el negro se menea _NL_ Te vuelves loca cuando _NL_ Bailotea, machequea _NL_ Como el negro se menea _NL_ Y que el negro se menea… _NL_ Se menea, se menea, se menea _NL_ Se menea, se menea, se menea _NL_ Se menea _NL_ Te vuelves loca cuando _NL_ Bailotea, machequea _NL_ Como el negro se menea _NL_ Te vuelves loca cuando _NL_ Bailotea, machequea _NL_ Como el negro se menea(Eso lo sabe to' el mundazo _NL_ Yo que tu le digo al palomo _NL_ Que recoja' las plumas y los huevitos _NL_ Que fue salido del guaraguao boricua) _NL_ (Esto es King of Kings) _NL_ (yo soy Don papi) _NL_ (El mas tigre _NL_ El mas tigre!) _NL_ (Eliel! _NL_ Julian _NL_ Esta to' frio! _NL_ Tu sabes _NL_ Que esta to' frio) _NL_ (Eso lo sabe to' el mundazo _NL_ Yo que tu le digo al palomo _NL_ Que recoja' las plumas y los huevitos _NL_ Que fue salido del guaraguao boricua) _NL_ (Esto es King of Kings) _NL_ (yo soy Don papi) _NL_ (El mas tigre _NL_ El mas tigre!) _NL_ (Eliel! _NL_ Julian _NL_ Esta to' frio! _NL_ Tu sabes _NL_ Que esta to' frio)Anda vamos… _NL_ Cuentale de tu y yo _NL_ Y de una vez confiesale _NL_ Que te perdio _NL_ Anda vamos… _NL_ Cuentale de tu y yo _NL_ Y de una vez confiesale _NL_ Que te perdioAnda vamos… _NL_ Cuentale de esta pasion _NL_ Por que ya yo no esperare _NL_ O le dices tu, o le digo yo _NL_ Anda vamos… _NL_ Cuentale de esta pasion _NL_ Por que ya yo no esperare _NL_ O le dices tu, o le digo yoO le dices tu, o le digo yo _NL_ O le dices tu, o le digo yo _NL_ O le dices tu, o le digo yo _NL_ O le dices tu, o le digo yo _NL_ O le dices tu, o le digo yo _NL_ O le dices tu, o le digo yo _NL_ O le dices tu, o le digo yo _NL_ O le dices tu, o le digo yo _NL_ O le dices tu, o le digo yo _NL_ O le dices tu, o le digo yo _NL_ O le dices tu, o le digo yo _NL_ O le dices tu, o le digo yo _NL_ TORITO... _NL_  _NL_ TORITO... \n"
     ]
    }
   ],
   "source": [
    "print(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir(\"DonOmar/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load lyrics\n",
    "all_songs = []\n",
    "for name_file in all_files:\n",
    "    file = open(\"DonOmar/\" + name_file, 'r')\n",
    "    all_songs.append(file.read().replace(\"\\n\", new_line_sentinel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many songs?\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "poetry_tokenized = []\n",
    "for song in all_songs:\n",
    "    poetry_tokenized += nltk.word_tokenize(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natty', 'natasha', '_NL_', 'Ahora', 'entiendo', 'es', 'tan', 'difícil', 'de', 'aceptar', '_NL_', 'Que', 'tuvimos', 'tanto', 'para', 'dar', '_NL_', 'Y', 'con', 'el', 'tiempo', 'se', 'acabo', 'nuestro', 'camino', '_NL_', '_NL_', 'Natty', 'natasha', '_NL_', 'Ahora', 'entiendo', 'es', 'tan', 'difícil', 'de', 'aceptar', '_NL_', 'Que', 'tuvimos', 'tanto', 'para', 'dar', '_NL_', 'Y', 'con', 'el', 'tiempo', 'se', 'acabo', 'nuestro', 'camino', '_NL_', 'Ahora', 'entiendo', 'es', 'tan', 'difícil', 'de', 'aceptar', '_NL_', 'Que', 'tuvimos', 'tanto', 'para', 'dar', '_NL_', 'Y', 'con', 'el', 'tiempo', 'se', 'acabo', 'nuestro', 'caminoDon', 'omar', '_NL_', 'Que', 'paraíso', 'construimos', 'si', 'al', 'final', '_NL_', 'Termino', 'por', 'derribarnos', 'la', 'ansiedad', '_NL_', 'No', 'supimos', 'rescatarnos', 'y', 'cambio', 'nuestro', 'destino', '_NL_', 'Don', 'omar']\n"
     ]
    }
   ],
   "source": [
    "# First 100 tokens\n",
    "print(poetry_tokenized[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some poetry: build language model and generate!\n",
    "\n",
    "# Our model will be a dictionary that maps trigram -> number of occurrences in reuters data\n",
    "# By default we have zero for all trigrams (this is why we use defaultdict and not dict)\n",
    "poetry_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    " \n",
    "\n",
    "# For each trigram in the sentence\n",
    "for w1, w2, w3 in trigrams(poetry_tokenized, pad_right=True, pad_left=True):\n",
    "    # Increase occurence count\n",
    "    poetry_model[(w1, w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute probabilities from counts\n",
    "for w1_w2 in poetry_model:\n",
    "    total_count = float(sum(poetry_model[w1_w2].values()))\n",
    "    for w3 in poetry_model[w1_w2]:\n",
    "        # Divide the number of times a trigram appears by the total count of trigrams\n",
    "        poetry_model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the common words that follow \"el tiempo\"?\n",
    "# poetry_model[\"\", \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute probabilities from counts\n",
    "for w1_w2 in poetry_model:\n",
    "    total_count = float(sum(poetry_model[w1_w2].values()))\n",
    "    for w3 in poetry_model[w1_w2]:\n",
    "        # Divide the number of times a trigram appears by the total count of trigrams\n",
    "        poetry_model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tu sabe \n",
      " Don danni ... Danni fornari \n",
      " Luny , la batidora \n",
      " Batidora , La muerte llego pronto \n",
      " wooo jaa \n",
      " Oye , Don , Dale ! ) Aguanta tu donqueo \n",
      " ( que te choque \n",
      " No juegues con tu gorío , sandungueando , esto es un\n"
     ]
    }
   ],
   "source": [
    "new_line_sentinel = \"_NL_\"\n",
    "poetry = [\"tu\", \"sabe\"]\n",
    "\n",
    "for i in range(1, 50):\n",
    "\n",
    "    # Obtain predictions for next word based on the lastest 2 words\n",
    "    predictions = poetry_model[tuple(poetry[-2:])]\n",
    "\n",
    "    prediction_items = predictions.items()\n",
    "    probs = [p[1] for p in prediction_items]\n",
    "    words = [p[0] for p in prediction_items]\n",
    "    \n",
    "    # Randomly select next word considering conditional probabilities\n",
    "    s = np.random.multinomial(1, probs)\n",
    "    candidate = list(compress(words, s))[0]\n",
    "    poetry.append(candidate)\n",
    "\n",
    "\n",
    "print(\" \".join(poetry).replace(new_line_sentinel, \"\\n\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want more tasks?\n",
    "Wanna try an other text representation? \n",
    "- Tf–idf\n",
    "- What about taking in to account stop words? \n",
    "\n",
    "Resources: https://scikit-learn.org/stable/modules/feature_extraction.html?highlight=nlp#text-feature-extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
